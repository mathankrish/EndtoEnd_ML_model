{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db26fe71-8a39-49c1-97e4-065d8e542fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.43.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.10/site-packages (2.5.0)\n",
      "Collecting kfp\n",
      "  Downloading kfp-2.7.0.tar.gz (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.8/441.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-cloud-pipeline-components\n",
      "  Downloading google_cloud_pipeline_components-2.11.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.28.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.18.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.3)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: click<9,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (8.1.7)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.10/site-packages (from kfp) (0.15)\n",
      "Collecting kfp-pipeline-spec==0.3.0 (from kfp)\n",
      "  Downloading kfp_pipeline_spec-0.3.0-py3-none-any.whl.metadata (329 bytes)\n",
      "Requirement already satisfied: kfp-server-api<2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (2.0.5)\n",
      "Requirement already satisfied: kubernetes<27,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (26.1.0)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-aiplatform)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/lib/python3.10/site-packages (from kfp) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (0.10.1)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (1.26.18)\n",
      "Requirement already satisfied: Jinja2<4,>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pipeline-components) (3.1.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.0)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=3.1.2->google-cloud-pipeline-components) (2.0.1)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.1.0,>=2.0.0->kfp) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.1.0,>=2.0.0->kfp) (2024.2.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<27,>=8.0.0->kfp) (69.1.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<27,>=8.0.0->kfp) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<27,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.6)\n",
      "Requirement already satisfied: numpy<2,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<27,>=8.0.0->kfp) (3.2.2)\n",
      "Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kfp_pipeline_spec-0.3.0-py3-none-any.whl (12 kB)\n",
      "Downloading google_cloud_pipeline_components-2.11.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kfp\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-2.7.0-py3-none-any.whl size=610418 sha256=1dee336571e909f2d58a3201ada663735b383f4347a696c7800d5a4b803021f3\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/9e/7d/a4/f9d013e82681c9746ef10de3b00456163577a99279c5ed673d\n",
      "Successfully built kfp\n",
      "Installing collected packages: protobuf, kfp-pipeline-spec, google-api-core, google-cloud-storage, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: kfp-pipeline-spec\n",
      "    Found existing installation: kfp-pipeline-spec 0.2.2\n",
      "    Uninstalling kfp-pipeline-spec-0.2.2:\n",
      "      Successfully uninstalled kfp-pipeline-spec-0.2.2\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 2.5.0\n",
      "    Uninstalling kfp-2.5.0:\n",
      "      Successfully uninstalled kfp-2.5.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.43.0\n",
      "    Uninstalling google-cloud-aiplatform-1.43.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.43.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.18.0 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-language 1.3.2 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "google-cloud-pubsub 2.20.1 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.48.1 which is incompatible.\n",
      "google-cloud-videointelligence 1.16.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.11.1 google-cloud-aiplatform-1.44.0 google-cloud-pipeline-components-2.11.0 google-cloud-storage-2.16.0 kfp-2.7.0 kfp-pipeline-spec-0.3.0 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade  google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 kfp \\\n",
    "                                 google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95eb22b7-3e3c-40aa-a6a1-5abc4ce4fb49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[core]\n",
      "account = 617832854196-compute@developer.gserviceaccount.com\n",
      "disable_usage_reporting = True\n",
      "project = end2end-416809\n",
      "\n",
      "Your active configuration is: [default]\n"
     ]
    }
   ],
   "source": [
    "!gcloud config list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346c2dfa-b8d0-498f-9f0c-3ade4f8ea5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"end2end-416809\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313bdf34-e000-4ac0-8559-038e16aafd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp import compiler\n",
    "from kfp.dsl import InputPath, Model, OutputPath, component\n",
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625aa64e-1a1e-4dae-8a28-29ef6c76faca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing AI platform\n",
    "BUCKET_URI = \"gs://kfp-churn-bucket\"\n",
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55f3310-cf20-4948-9eab-fb49d6096b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(base_image='python:3.12', packages_to_install = [\"pandas==2.1.4\", \"fsspec==2024.3.1\",\"gcsfs\"])\n",
    "def prepare_data(output_csv: OutputPath(), \n",
    "                 train1_csv_url: str \n",
    "                 ) -> None:\n",
    "    \n",
    "    import pandas as pd\n",
    "    print(\"---- Inside prepare_data component ----\")\n",
    "    # Load dataset\n",
    "    train1 = pd.read_csv(train1_csv_url)\n",
    "    \n",
    "    with open(output_csv, 'w') as f:\n",
    "        train1.to_csv(f, index=False)\n",
    "    # print(\"\\n ---- data csv is saved to PV location /data/final_df.csv ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4b9abf-9a36-41be-84aa-6c3fa7dafd90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(base_image='python:3.12', \n",
    "               packages_to_install = [\"pandas==2.1.4\", \"scikit-learn\", \"numpy\", \"fsspec==2024.3.1\", \"gcsfs\"])\n",
    "def train_test_split(cc_data_csv: InputPath(), \n",
    "                     train_csv: OutputPath(), \n",
    "                     test_csv: OutputPath(), \n",
    "                     target: str) -> None:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    print(\"---- Inside train_test_split component ----\")\n",
    "    with open(cc_data_csv) as f:\n",
    "        final_data = pd.read_csv(f)\n",
    "    \n",
    "    train_df, test_df = train_test_split(final_data, test_size=0.3,stratify = final_data[target], random_state=47)\n",
    "\n",
    "    with open(train_csv, 'w') as f:\n",
    "        train_df.to_csv(f, index=False)\n",
    "\n",
    "    with open(test_csv, 'w') as f:\n",
    "        test_df.to_csv(f, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe90d1e-3eb8-4ff4-9b97-ae8a5c751bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(base_image='python:3.12', \n",
    "               packages_to_install = [\"pandas==2.1.4\", \"scikit-learn\", \"numpy\", \"fsspec==2024.3.1\",\"gcsfs\"])\n",
    "def training_basic_classifier(train_csv: InputPath(), \n",
    "                              trained_model: OutputPath(), \n",
    "                              target_column: str) -> None:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    \n",
    "    print(\"---- Inside training_basic_classifier component ----\")\n",
    "    \n",
    "    with open(train_csv) as f:\n",
    "        df = pd.read_csv(f)\n",
    "    target = target_column\n",
    "    df = df.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    features = df.drop(target, axis= 1)\n",
    "    ytrain = df[target]\n",
    "    \n",
    "    input_median = SimpleImputer(missing_values=np.nan, strategy ='median')\n",
    "    xtrain = input_median.fit_transform(features)\n",
    "\n",
    "    classifier = LogisticRegression(max_iter=500)\n",
    "    classifier.fit(xtrain,ytrain)\n",
    "    import pickle\n",
    "    with open(trained_model, 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "    \n",
    "    print(\"\\n logistic regression classifier is trained on iris data and saved to PV location /data/model.pkl ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fed4cdb-198d-4f41-abe7-40f928ea433d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(base_image='python:3.12', \n",
    "               packages_to_install = [\"pandas==2.1.4\", \"scikit-learn\", \"numpy\", \"fsspec==2024.3.1\",\"gcsfs\"])\n",
    "def predict_on_test_data(trained_model: InputPath(), \n",
    "                         test_csv: InputPath(),\n",
    "                         y_pred_csv: OutputPath(), \n",
    "                         target:str) -> None:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    print(\"---- Inside predict_on_test_data component ----\")\n",
    "\n",
    "    with open(test_csv,'rb') as f:\n",
    "        test_df = pd.read_csv(f)\n",
    "        \n",
    "    with open(trained_model,'rb') as f:\n",
    "        logistic_reg_model = pickle.load(f)\n",
    "        \n",
    "    df = test_df.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    features = df.drop(target, axis= 1)\n",
    "    input_median = SimpleImputer(missing_values=np.nan, strategy ='median')\n",
    "    \n",
    "    xtest = input_median.fit_transform(features)\n",
    "    ytest = df[target]\n",
    "\n",
    "    y_pred = logistic_reg_model.predict(xtest)\n",
    "    y_pred_df = pd.DataFrame(y_pred)\n",
    "    print(y_pred)\n",
    "\n",
    "    with open(y_pred_csv, 'w') as f:\n",
    "        y_pred_df.to_csv(f, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2771ebf-110c-42f2-a376-f1e56fda7e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(base_image='python:3.12', \n",
    "               packages_to_install = [\"pandas==2.1.4\", \"scikit-learn\", \"numpy\", \"fsspec==2024.3.1\",\"gcsfs\"])\n",
    "def get_metrics(trained_model: InputPath(), \n",
    "                         test_csv: InputPath(),\n",
    "                         y_pred_csv: InputPath(), \n",
    "                         target:str) -> None:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    from sklearn import metrics\n",
    "    import pickle\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    print(\"---- Inside get_metrics component ----\")\n",
    "\n",
    "    with open(test_csv) as f:\n",
    "        test_df = pd.read_csv(f)\n",
    "    df = test_df.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    with open(trained_model,'rb') as f:\n",
    "        logistic_reg_model = pickle.load(f)\n",
    "\n",
    "    with open(y_pred_csv,'rb') as f:\n",
    "        y_pred_df = pd.read_csv(f)\n",
    "\n",
    "    y_pred = y_pred_df.to_numpy()\n",
    "\n",
    "    y_test = df[target]\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred,average='micro')\n",
    "    recall = recall_score(y_test, y_pred,average='micro') \n",
    "    \n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\n Model Metrics:\", {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbc730c-30c5-4853-bffc-a7cb0a76737e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='Credit Card Fraud Detection classifier Kubeflow Demo Pipeline',\n",
    "   description='A sample pipeline that performs Credit Card Fraud Detection classifier task'\n",
    ")\n",
    "# Define parameters to be fed into pipeline\n",
    "def credit_card_fraud_detection_pipeline():\n",
    "    \n",
    "    target = \"isFraud\"\n",
    "    train_transaction = \"gs://credit-card-bucket-v1/credit-card-fraud-detection-data.csv\"\n",
    "    # train_identity = \"gs://kfp-churn-bucket/train_transaction.csv\"\n",
    "    \n",
    "    prepare_data_task = prepare_data(train1_csv_url= train_transaction)\n",
    "    \n",
    "    train_test_split_data = train_test_split(cc_data_csv = prepare_data_task.outputs[\"output_csv\"], target=target).after(prepare_data_task)\n",
    "    \n",
    "    classifier_training = training_basic_classifier(train_csv= train_test_split_data.outputs[\"train_csv\"], target_column= target).after(train_test_split)\n",
    "    \n",
    "    log_predicted_class = predict_on_test_data(trained_model= classifier_training.outputs[\"trained_model\"], \n",
    "                         test_csv= train_test_split_data.outputs[\"test_csv\"],target = target).after(classifier_training)\n",
    "    \n",
    "    log_metrics_task = get_metrics(trained_model= classifier_training.outputs[\"trained_model\"], \n",
    "                         test_csv = train_test_split_data.outputs[\"test_csv\"],\n",
    "                         y_pred_csv= log_predicted_class.outputs[\"y_pred_csv\"], \n",
    "                         target = target).after(log_predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5c9a48-b68c-4126-9aca-8f7c0a44617e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=credit_card_fraud_detection_pipeline,\n",
    "    package_path='credit_card_fraud_detection.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdba119-3d49-42fa-a9e6-60340abb316b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = aip.PipelineJob(\n",
    "    display_name=\"credi-card-fraud-detection\",\n",
    "    template_path=\"credit_card_fraud_detection.yaml\",\n",
    "    enable_caching = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d17d0d-233a-4615-9d0d-240dc5157a20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901?project=617832854196\n",
      "PipelineJob projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617832854196/locations/us-central1/pipelineJobs/credit-card-fraud-detection-classifier-kubeflow-demo-pipeline-20240323101901\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e2626-70d7-4aaf-bcfe-756a42678b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m118"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
